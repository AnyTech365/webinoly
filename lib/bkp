#!/bin/bash

bkp_local_db() {
	check_for_mysql_client
	
	[[ -z $wp || $wp == "true" ]] &&	read -p "${gre}WordPress site: ${end}" wp
	
	wp_dbdata $wp
	if [[ -z $wp || $(is_wp $wp $subfolder) != "true"  ]]; then
		echo "${red}[ERROR] Please, enter a valid WP site!${end}"
		exit 1
	elif [[ $(is_wp_installed $wp) != "true"  ]]; then
		echo "${red}[ERROR] Your WP site database is still empty!${end}"
		exit 1
	fi
	
	[[ -z $destination || $destination == "true" ]] && read -p "${gre}Destination: ${end}" destination
	if [[ $destination == "default" ]]; then
		destination="$HOME/webinoly-backups/$wp"
		sudo mkdir -p $destination
	fi
	if [[ -z $destination || ! -d $destination || $(echo "${destination}" | rev | cut -c-1) == "/" ]]; then
		echo "${red}[ERROR] Please, enter a valid destination path!${end}"
		exit 1
	fi
	
	local filename="webinoly-backup-db_${wp}_$(date +%F)-$(date +%T).sql"
	if [[ $wp_dbhost == "localhost" ]]; then
		local adminpass=$( echo $(conf_read mysql-admin) | openssl enc -d -a -salt )
		sudo mysqldump --user=admin --password=$adminpass --single-transaction --lock-tables --quick --databases $wp_dbname > $destination/$filename
	else
		sudo mysqldump -h "$wp_dburl" -P "$wp_dbport" -u"$wp_uroot" -p"$wp_proot" --single-transaction --lock-tables --quick --databases $wp_dbname > $destination/$filename
	fi
	
	if [[ -s $destination/$filename ]]; then
		echo "${gre}Database local backup successfully done!${end}"
		[[ -n $bucket ]] && sudo webinoly -backup=s3 -send-to-s3=$destination/$filename -bucket=$bucket
		[[ -n $max && $max =~ ^[0-9]+$ ]] && sudo ls -1t $destination | tail -n +$((max+1)) | xargs -d '\n' -I '%' sudo rm -f $destination/%
	else
		echo "${red}[ERROR] Database backup failed!${end}"
		exit 1
	fi
}


check_duply_profile() {
	if [[ ! -d $HOME/.duply/$profile ]]; then
		echo "${red}[ERROR] Backup profile not found!${end}"
		exit 1
	fi
}


bkp_s3_profile() {
	if [[ ! -s $HOME/.aws/credentials && $(conf_read awsiamrole) != true ]]; then
		echo "${red}[ERROR] AWS S3 Credentials not found!${end}"
		exit 1
	fi
	
	if [[ $profile == "true" || -z $profile ]]; then
		echo ""
		read -p "${gre}Profile name: ${end}" profile
		
		if [[ -z $profile ]]; then
			echo "${red}[ERROR] Profile name is empty!${end}"
			exit 1
		fi
	fi
	
	
	if [[ -n $run ]]; then
		check_duply_profile
		sudo duply $profile backup_verify_purge --force --allow-source-mismatch
		
	elif [[ -n $info ]]; then
		check_duply_profile
		
		tar=$(grep -E "^TARGET[ ]?=" $HOME/.duply/$profile/conf | cut -f 2 -d "'" )
		sou=$(grep -E "^SOURCE[ ]?=" $HOME/.duply/$profile/conf | cut -f 2 -d "'" )
		age=$(grep -E "^MAX_AGE[ ]?=" $HOME/.duply/$profile/conf | cut -f 2 -d "=" )
		par=$(grep "s3-use-new-style" $HOME/.duply/$profile/conf | cut -f 2 -d '"' )
			
		echo ""
		echo "${blu}S3 Bucket:${end} $tar"
		echo "${blu}Source:${end} $sou"
		echo "${blu}Max_Age:${end} $age"
		echo "${blu}Parameters:${end} $par"
		echo ""
	
	elif [[ -n $delete ]]; then
		check_duply_profile
		
		sudo rm -rf $HOME/.duply/$profile
		echo "${gre}Backup profile ${blu}'$profile'${gre} was successfully deleted!${end}"
		
	elif [[ -n $restore ]]; then
		check_duply_profile
		
		if [[ $restore == "true" ]]; then
			echo ""
			read -p "${gre}Restore destination folder: ${end}" restore
		fi
		if [[ ! -d $restore ]]; then
			echo "${red}[ERROR] Restore destination folder not found!${end}"
			exit 1
		fi
		
		sudo duply $profile restore $restore $date
	elif [[ -n $add_db_pre ]]; then
		check_duply_profile
		
		[[ $add_db_pre == "true" ]] &&	read -p "${gre}WordPress site: ${end}" add_db_pre
		# we dont check is_wp_installed because at this point we are still not doing a backup, just setting it.
		if [[ -z $add_db_pre || $(is_wp $add_db_pre $subfolder) != "true"  ]]; then
			echo "${red}[ERROR] Please, enter a valid WP site!${end}"
			exit 1
		fi
		
		wp_dbdata $add_db_pre
		if [[ $wp_dbhost != "localhost" ]]; then
			echo "${red}[ERROR] Database host is not localhost!${end}"
			exit 1
		fi
		
		[[ -z $destination || $destination == "true" ]] && destination="default"
		[[ -z $max && $destination == "default" ]] && max="5"
		[[ -n $max && $max =~ ^[0-9]+$ ]] && local param="-max=$max "
		[[ -n $bucket && $bucket != "true" ]] && local param="${param}-bucket=$bucket "
		[[ -n $subfolder ]] && local param="${param}-subfolder=$subfolder"
		
		[[ ! -f $HOME/.duply/$profile/pre ]] && sudo touch $HOME/.duply/$profile/pre
		echo "sudo webinoly -backup=local -wp=$add_db_pre -destination=$destination $param" >> $HOME/.duply/$profile/pre
		echo "${gre}Database backup will run each time you run your S3 backup!${end}"
	
	else
		if [[ -d $HOME/.duply/$profile ]]; then
			echo "${red}[ERROR] Can not create profile${blu} '$profile' ${red}because already exists!${end}"
			exit 1
		fi
	
		[[ -z $bucket || $bucket == "true" ]] &&	read -p "${gre}S3 Bucket name: ${end}" bucket
		# Only numerals 0-9, basic Latin letters (only lowercase) and underscore.
		if ! [[ $bucket =~ ^[0-9a-z\/-]+$ ]] || [[ -z $bucket || $(echo "$bucket" | cut -c-1) =~ [-|\/] || ${#bucket} -gt 63 || ${#bucket} -lt 3 ]]; then
			echo "${red}[ERROR] Bucket names can only contain lowercase letters, numbers or hyphens; must start with a letter or number and must be at least 3 and no more than 63 characters long.${end}"
			exit 1
		fi
		
		[[ -z $source || $source == "true" ]] && read -p "${gre}Source path: ${end}" source
		if [[ -z $source || ! -d $source ]]; then
			echo "${red}[ERROR] Please, enter a valid source folder and bucket name!${end}"
			exit 1
		fi
		
		sudo duply $profile create
		[[ -z $max_age ]] && max_age="1M"
		sudo sed -i -E "/^[#]?GPG_KEY=/c GPG_KEY='disabled'" $HOME/.duply/$profile/conf
		sudo sed -i -E "/^[#]?GPG_PW=/c #GPG_PW='_GPG_PASSWORD_'" $HOME/.duply/$profile/conf
		sudo sed -i -E "/^[#]?TARGET=/c TARGET='s3+http://${bucket}'" $HOME/.duply/$profile/conf
		sudo sed -i -E "/^[#]?SOURCE=/c SOURCE='$source'" $HOME/.duply/$profile/conf
		sudo sed -i -E "/^[#]?MAX_AGE=/c MAX_AGE=$max_age" $HOME/.duply/$profile/conf
		
		if [[ -z $s3_european_buckets ]]; then
			sudo echo 'DUPL_PARAMS="$DUPL_PARAMS --s3-use-new-style "' >> $HOME/.duply/$profile/conf
		else
			sudo echo 'DUPL_PARAMS="$DUPL_PARAMS --s3-use-new-style --s3-european-buckets "' >> $HOME/.duply/$profile/conf
		fi
		
		echo "${gre}Backup profile ${blu}'$profile'${gre} was successfully created!${end}"
	fi
}


bkp_s3_list() {
	echo ""
	if [[ -d $HOME/.duply ]];  then
		for f in $HOME/.duply/*
		do 
			[[ -d $f ]] && pro=$(echo $f | rev | cut -f 1 -d "/" -s | rev)
			[[ -f $f/conf ]] && fail="" || fail="${red}(fail)${end}"
			[[ -n $raw || $list == "raw" ]] && outlist="$pro" || outlist=" ${gre}+ $pro ${end}${fail}"
			if [[ -n $outlist ]]; then
				echo "$outlist"
				nonemptylist=true
			fi
		done
	fi
	
	[[ -z $nonemptylist && -z $raw && $list != "raw" ]] && echo "${blu}[Empty] No profiles were found!${end}"
	echo ""
}


s3_send() {
	if [[ ! -s $HOME/.aws/credentials && $(conf_read awsiamrole) != true ]]; then
		echo "${red}[ERROR] AWS S3 Credentials not found!${end}"
		exit 1
	fi
	
	[[ -z $send_to_s3 || $send_to_s3 == "true" ]] && read -p "${gre}File to send: ${end}" send_to_s3
	if [[ ! -f $send_to_s3 ]]; then
		echo "${red}[ERROR] File not found!${end}"
		exit 1
	fi
	
	[[ -z $bucket || $bucket == "true" ]] &&	read -p "${gre}S3 Bucket name: ${end}" bucket
	# Only numerals 0-9, basic Latin letters (only lowercase) and underscore.
	if ! [[ $bucket =~ ^[0-9a-z\/-]+$ ]] || [[ -z $bucket || $(echo "$bucket" | cut -c-1) =~ [-|\/] || ${#bucket} -gt 63 || ${#bucket} -lt 3 ]]; then
		echo "${red}[WARNING] Seems like you're still using the old (deprecated) bucket naming schema."
		echo "https://docs.aws.amazon.com/AmazonS3/latest/dev/BucketRestrictions.html#bucketnamingrules${end}"
		#exit 1
	fi
	
	folder=$(echo $bucket | cut -f 2- -d "/" -s)
	[[ -n $folder ]] && folder="/${folder}/"
	
	export folder
	export bucket=$(echo $bucket | cut -f 1 -d "/")
	export send_to_s3
	
	python - &>/dev/null <<END
import os,boto

filepath = os.environ['send_to_s3']
BUCKET = os.environ['bucket']
folder = os.environ['folder']

conn = boto.connect_s3()
bucket = conn.lookup(BUCKET)
k = bucket.new_key(folder + filepath.split('/')[-1])
k.set_contents_from_filename(filepath)

END
	
	if [[ $? == 0 ]]; then
		unset send_to_s3
		unset folder
		unset bucket
		echo "${gre}File was sent to S3 successfully!${end}"
	else
		unset send_to_s3
		unset folder
		unset bucket
		echo "${red}[ERROR] Can not connect with your bucket!${end}"
		exit 1
	fi
	
}


bkp_wizard() {
	echo "${gre}"
	echo " ***********************************"
	echo " ************  Backups  ************"
	echo " ***********************************"
	echo "${blu}"
	echo " 1 - Add AWS S3 Credentials"
	echo " 2 - AWS S3 directory backup"
	echo " 3 - WordPress Database local backup"
	echo " 4 - Restore backup from S3"
	echo " 5 - Run S3 backup"
	echo " 6 - Delete profile"
	echo " 7 - Profile info"
	echo " 8 - List profiles"
	echo "${gre}"
	read -p "What do you want to do? ${end}" wzd
	echo ""
	
	if [[ $wzd == 1 ]]; then
		webinoly -aws-s3-credentials
	elif [[ $wzd == 2 ]]; then
		bkp_s3_profile
	elif [[ $wzd == 3 ]]; then
		bkp_local_db
	elif [[ $wzd == 4 ]]; then
		restore="true"
		bkp_s3_profile
	elif [[ $wzd == 5 ]]; then
		run="true"
		bkp_s3_profile
	elif [[ $wzd == 6 ]]; then
		delete="true"
		bkp_s3_profile
	elif [[ $wzd == 7 ]]; then
		info="true"
		bkp_s3_profile
	elif [[ $wzd == 8 ]]; then
		bkp_s3_list
	else
		echo "${red}[ERROR] Please, enter a valid option!${end}"
		exit 1
	fi
}
